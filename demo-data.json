{
  "skills": [
    {
      "org": "engram-hq",
      "repo": ".skills",
      "tier": 2,
      "path": "org-knowledge/SKILL.md",
      "name": "SKILL.md",
      "content": "---\nname: engram-hq-org-knowledge\ndescription: |\n  Organization knowledge for the Engram platform - a Skill & Memory Browser for AI Agents.\n  Covers architecture, conventions, and cross-repo patterns.\nlast_updated: 2026-02-12\n---\n\n# Engram Platform Architecture\n\n## Overview\n\nEngram is a multi-tenant SaaS platform that indexes and visualizes AI agent skills and memories stored across GitHub repositories. It provides cost analytics for AI agent operations.\n\n## Repositories\n\n- **engram-web**: Next.js 16 web application + REST API (primary)\n- **.skills**: This repository - org-level knowledge base\n\n## Tech Stack\n\n- **Framework**: Next.js 16 (App Router) + React 19\n- **Database**: Turso (SQLite via libSQL) + Drizzle ORM\n- **Auth**: Auth.js v5 with GitHub OAuth + API key auth for agents\n- **UI**: shadcn/ui + Tailwind v4 + Recharts\n- **GitHub Integration**: Octokit REST API\n- **Markdown**: react-markdown v10 + rehype-highlight\n\n## Architecture Decisions\n\n### Dual Authentication\n- Web users: GitHub OAuth via Auth.js v5 \u2192 session cookies\n- AI agents: API keys with `eng_` prefix \u2192 Bearer token\n- `authenticateRequest()` checks Bearer first, session fallback\n\n### 3-Tier Skill Hierarchy\n1. **User level** (Tier 1): Cross-org skills in user's skills repo\n2. **Org level** (Tier 2): Org-specific skills in `<org>/.skills`\n3. **Repo level** (Tier 3): Project-specific skills in `<repo>/.skills/`\n\n### Database Design\n- 10 tables in Turso (SQLite)\n- Content hashing (SHA-256) for incremental sync\n- Daily rollup tables for fast analytics queries\n- FTS5 virtual tables for full-text search\n\n### Agent Metrics\n- POST /v1/metrics/ingest for single/batch event ingestion\n- Server-side cost calculation from model_pricing table\n- Daily rollups via upsert with atomic SQL increments\n\n## Conventions\n\n- All IDs are hex(randomblob(16))\n- API keys: `eng_` prefix + 32 random hex bytes, stored as SHA-256 hash\n- Tokens encrypted with AES-256-GCM (IV:authTag:ciphertext format)\n- Content hash: SHA-256 for change detection during sync\n- Memory types: session, cumulative, reference (inferred from path and content)\n\n## Known Issues\n\n- ReactMarkdown v10 removed className prop - wrap in div\n- Edge Runtime can't import Node.js crypto - handle auth in API routes\n- Auth.js v5 profile.id is string|null|undefined - use Number()\n"
    },
    {
      "org": "engram-hq",
      "repo": ".skills",
      "tier": 2,
      "path": "cost-tracking/SKILL.md",
      "name": "SKILL.md",
      "content": "---\nname: session-cost-tracking\ndescription: |\n  Automatically extract and save AI agent cost metrics from Claude Code sessions\n  into session memory frontmatter. Enables real cost analytics in Engram.\n  MANDATORY: When creating or updating a session memory file, include cost metrics.\nlast_updated: 2026-02-12\n---\n\n# Session Cost Tracking\n\n## Purpose\n\nEvery session memory file MUST include real cost metrics in its YAML frontmatter.\nThis enables Engram to render accurate cost analytics from authentic data -\nno estimates, no assumptions, no fabricated numbers.\n\n## Required Frontmatter Fields\n\nWhen writing a session memory file (`<org>/.memory/sessions/YYYY-MM-DD-<slug>.md`),\ninclude these fields in the YAML frontmatter:\n\n```yaml\n---\ndate: \"2026-02-12\"\norg: my-org\nrepo: my-repo\ngoal: What this session accomplished\ntype: session\nmodel: claude-opus-4-6\ninput_tokens: 36533\noutput_tokens: 97287\ncache_read_tokens: 130057002\ncache_creation_tokens: 3267470\ncost_usd: 88.07\nduration_minutes: 180\napi_calls: 1320\n---\n```\n\n### Field Definitions\n\n| Field | Type | Source | Required |\n|-------|------|--------|----------|\n| `model` | string | `message.model` from session JSONL | Yes |\n| `input_tokens` | integer | Sum of `usage.input_tokens` across all assistant messages | Yes |\n| `output_tokens` | integer | Sum of `usage.output_tokens` across all assistant messages | Yes |\n| `cache_read_tokens` | integer | Sum of `usage.cache_read_input_tokens` | Yes |\n| `cache_creation_tokens` | integer | Sum of `usage.cache_creation_input_tokens` | Yes |\n| `cost_usd` | float | Calculated using pricing formula below | Yes |\n| `duration_minutes` | integer | Approximate session duration | Recommended |\n| `api_calls` | integer | Count of assistant messages in session | Recommended |\n\n## Data Sources\n\n### 1. Session JSONL Files (Primary)\n\nClaude Code stores every session at:\n```\n~/.claude/projects/<project-slug>/<session-id>.jsonl\n```\n\nEach line is a JSON record. Records with `type: \"assistant\"` contain:\n```json\n{\n  \"type\": \"assistant\",\n  \"message\": {\n    \"model\": \"claude-opus-4-6\",\n    \"usage\": {\n      \"input_tokens\": 36533,\n      \"output_tokens\": 97287,\n      \"cache_read_input_tokens\": 130057002,\n      \"cache_creation_input_tokens\": 3267470,\n      \"cache_creation\": {\n        \"ephemeral_5m_input_tokens\": 0,\n        \"ephemeral_1h_input_tokens\": 3267470\n      },\n      \"output_tokens\": 97287,\n      \"service_tier\": \"standard\"\n    }\n  }\n}\n```\n\nSum all `usage` fields across all assistant messages in the session to get totals.\n\n### 2. Stats Cache (Aggregate)\n\n`~/.claude/stats-cache.json` contains aggregate data:\n- `modelUsage`: Total tokens per model (all-time)\n- `dailyActivity`: Messages, sessions, tool calls per day\n- `dailyModelTokens`: Output tokens per model per day\n\n### 3. Anthropic Admin API (Organization-level)\n\nFor API key users (not Max plan), the Admin API provides server-side billing data:\n- `GET /v1/organizations/usage_report/messages` - token usage by day/model/key\n- `GET /v1/organizations/cost_report` - dollar costs by day/model/key\n\nRequires an Admin API key (`sk-ant-admin...`).\n\n## Cost Calculation Formula\n\n### Published Pricing (per million tokens, USD)\n\n| Model | Input | Output | Cache Read | Cache Write (5min) | Cache Write (1hr) |\n|-------|-------|--------|------------|--------------------|--------------------|\n| Claude Opus 4.6 | $5 | $25 | $0.50 | $6.25 | $10 |\n| Claude Opus 4.5 | $5 | $25 | $0.50 | $6.25 | $10 |\n| Claude Sonnet 4.5 | $3 | $15 | $0.30 | $3.75 | $6 |\n| Claude Haiku 4.5 | $1 | $5 | $0.10 | $1.25 | $2 |\n\n### Formula\n\n```python\n# Default: assume 5-minute ephemeral cache (most common in Claude Code)\ncost_usd = (\n    input_tokens * input_price +\n    output_tokens * output_price +\n    cache_read_tokens * cache_read_price +\n    cache_creation_tokens * cache_write_5m_price\n) / 1_000_000\n```\n\n### For Max Plan Users\n\nMax plan subscriptions report `costUSD: 0` in local stats. The formula above\ncalculates the **equivalent API cost** - what the session would cost at\nstandard API pricing. This is useful for:\n- Understanding relative session costs (which sessions are expensive)\n- Projecting costs for API-key-based deployments\n- Comparing model efficiency (Opus vs Sonnet for similar tasks)\n\nNote this in the memory frontmatter:\n```yaml\ncost_usd: 88.07  # equivalent API cost (Max plan subscriber)\n```\n\n## Projected Cost Calculation\n\nUse historical session data to project future costs:\n\n```python\navg_cost_per_session = total_cost / total_sessions\nsessions_per_day = total_sessions / active_days\nprojected_monthly = avg_cost_per_session * sessions_per_day * 30\nprojected_annual = projected_monthly * 12\n```\n\nInclude in analytics when sufficient data exists (>= 5 sessions).\n\n## How to Extract Data\n\n### Option A: Inline (during session)\n\nAt the end of a Claude Code session, when writing a session memory:\n\n1. Identify the current session JSONL file from `~/.claude/projects/`\n2. Parse all assistant messages, sum usage fields\n3. Apply pricing formula\n4. Include in frontmatter\n\n### Option B: Helper Script\n\nRun `extract-session-costs.py` (in this skill directory) to retroactively\nextract cost data from all session JSONL files:\n\n```bash\npython3 extract-session-costs.py [--project-slug <slug>] [--output json|yaml]\n```\n\n### Option C: Engram SDK\n\nWhen the Engram SDK is integrated, it tracks costs automatically:\n```typescript\nengram.track({\n  operation: 'create',\n  modelId: 'claude-opus-4-6',\n  inputTokens: 36533,\n  outputTokens: 97287,\n  cacheReadTokens: 130057002,\n  cacheCreationTokens: 3267470,\n  durationMs: 10800000,\n})\n```\n\n## Cost Breakdown Insights\n\nFrom real session data, the typical cost distribution is:\n- **Cache reads: ~70%** of total cost (context re-reading)\n- **Cache writes: ~28%** (new context caching)\n- **Output tokens: ~1.5%** (model responses)\n- **Input tokens: <1%** (most input is cached)\n\nThis means the biggest cost driver is context size, not output length.\nShorter context windows dramatically reduce costs.\n\n## Integration with Engram\n\nSession memories with cost frontmatter are:\n1. Synced to Engram via GitHub Sync (scans `.memory/` repos)\n2. Rendered in the Analytics dashboard (cost charts, model breakdown)\n3. Used for projected cost calculations\n4. Searchable via Full-Text Search\n\nThe nightly CI workflow (`refresh-demo.yml`) picks up new data automatically\nand updates the live demo at https://engram-hq.github.io/releases/.\n"
    },
    {
      "org": "sreniatnoc",
      "repo": ".skills",
      "tier": 2,
      "path": "org-knowledge/SKILL.md",
      "name": "SKILL.md",
      "content": "---\nname: sreniatnoc-org-knowledge\ndescription: |\n  Knowledge base for sreniatnoc GitHub organization. Use this skill when:\n  - Working on any sreniatnoc repo\n  - Planning features, PRs, or commits\n  - Understanding repo purposes and relationships\n  MANDATORY: Consult before any sreniatnoc repo operation.\nlast_updated: 2026-02-10\n---\n\n# sreniatnoc Organization Knowledge\n\n## Organization Overview\n\n**Mission**: Open-source developer tools in Rust and Go.\n**GitHub**: https://github.com/sreniatnoc\n\n---\n\n## Repos\n\n### rusd (PUBLIC)\n**Purpose**: High-performance embedded database written in Rust with MVCC support. Etcd replacement.\n**Tech**: Rust 2021, gRPC (tonic 0.11/prost 0.12), sled, Docker\n**Repo**: https://github.com/sreniatnoc/rusd\n\n**Key Features**:\n- MVCC (Multi-Version Concurrency Control) storage engine (sled-backed)\n- etcd-compatible gRPC API (KV, Auth, Cluster, Watch, Lease, Maintenance)\n- Watch event delivery with prev_kv support\n- Txn CAS (Compare-and-Swap) operations\n- Raft consensus module (single-node works, multi-node event loop disabled)\n- Docker and Kubernetes support (Docker image 167MB)\n- HTTP/2 keepalive and graceful shutdown (serve_with_shutdown)\n- **Validated as K8s etcd backend** - Kind cluster with K8s v1.35 fully works\n\n**Key Directories**:\n- `src/api/` - 6 gRPC service implementations (kv, watch, lease, cluster, maintenance, auth)\n- `src/storage/` - MVCC storage engine (backend.rs, mvcc.rs, index.rs, compaction.rs)\n- `src/raft/` - Raft consensus (node.rs 677 lines, state.rs, log.rs, transport.rs)\n- `src/watch/` - WatchHub with DashMap + crossbeam channels (wired to KvService and WatchService)\n- `src/server/` - Server orchestration, startup, graceful shutdown\n- `proto/etcdserverpb/` - rpc.proto, kv.proto, auth.proto\n- `benches/` - Criterion benchmarks\n- `scripts/` - k8s-test.sh (492 lines), setup.sh (284 lines)\n- `tests/` - 12 integration tests (BROKEN: test HTTP endpoints but rusd is gRPC-only)\n- `.skills/kind-validation.md` - Kind cluster config and validation details\n\n**Docs**: `README.md`, `STORAGE_DESIGN.md`, `MVCC_IMPLEMENTATION.md`, `FILE_STRUCTURE.md`\n\n**Validated Status (2026-02-10)**:\n- Native build: OK (cargo build --release, ~8,300 lines Rust)\n- Docker build: OK (167MB, requires fixed Dockerfile)\n- Unit tests: 40/40 PASS (storage, mvcc, watch, lease, auth, compaction, raft)\n- Integration tests: 12/12 FAIL (tests use HTTP/JSON but rusd is gRPC-only, needs rewrite)\n- Kind cluster (K8s v1.35): WORKS - all CRUD operations validated\n\n**etcdctl Compatibility Matrix**:\n| API | Status | Notes |\n|-----|--------|-------|\n| KV Put | OK | Works with etcdctl |\n| KV Get | OK | Single key and prefix queries |\n| KV Delete | OK | Returns delete count |\n| Watch | OK | Prefix watch, PUT/DELETE events, prev_kv delivered |\n| Txn CAS | OK | Compare operations (version, create_rev, mod_rev, value) work |\n| Lease Grant | OK | TTL and ID returned |\n| Lease List | OK | Lists active leases |\n| Lease TimeToLive | OK | Returns remaining TTL |\n| Lease Revoke | PARTIAL | Revokes lease but keys NOT deleted (BUG) |\n| Endpoint Health | OK | Reports healthy |\n| Endpoint Status | FAIL | Panics in etcdctl (divide by zero) |\n| Member List | OK | Returns single-node member |\n| User Add | OK | Creates user |\n| Role Add | OK | Creates role |\n| User/Role List | EMPTY | Returns empty lists |\n\n**K8s Operations Validated (Kind, K8s v1.35)**:\n- Namespace create/delete, ConfigMap, Secret, ServiceAccount CRUD\n- Role, RoleBinding CRUD\n- Deployment create, scale (replicas), rolling update\n- Service creation, Pod exec\n- RBAC bootstraps correctly, all control plane components functional\n\n**Known Limitations**:\n- \"Too large resource version\" errors: non-fatal, K8s retries automatically\n- Revision-based range reads: MVCC stores latest only (not full history), sufficient for K8s\n- Integration tests: need rewrite from HTTP/JSON to gRPC (tonic client)\n- Lease revoke doesn't delete attached keys\n- Endpoint status response missing fields (causes etcdctl panic)\n\n**Dockerfile Fixes Applied**:\n- Added `COPY build.rs ./` (protobuf code generation)\n- Added `COPY proto proto/` (proto definitions)\n- Added `COPY benches benches/` and `COPY tests tests/` (Cargo.toml references them)\n- Updated `rust:1.75-slim` -> `rust:1.85-slim` (Cargo.lock v4 format)\n- Fixed `as` -> `AS` casing\n\n---\n\n### k8sify (PUBLIC)\n**Purpose**: Intelligent Docker Compose to Kubernetes migration tool.\n**Tech**: Go\n**Repo**: https://github.com/sreniatnoc/k8sify\n\n**Key Features**:\n- Cost analysis for K8s migration\n- Security scanning\n- Production patterns generation\n- Docker Compose \u2192 K8s manifest conversion\n\n---\n\n### publications (PRIVATE)\n**Purpose**: LinkedIn articles and publication artifacts for all sreniatnoc projects.\n**Repo**: https://github.com/sreniatnoc/publications\n\n**Structure**:\n```\npublications/\n\u251c\u2500\u2500 rusd/\n\u2502   \u2514\u2500\u2500 YYYY-MM-DD-<slug>/\n\u2502       \u251c\u2500\u2500 html/       # LinkedIn-safe HTML\n\u2502       \u251c\u2500\u2500 images/     # PNGs + SVG sources\n\u2502       \u2514\u2500\u2500 post.txt    # Short-form post text\n```\n\n**Rule**: Article artifacts (HTML, images, cover) go here, NOT in project repos. Code/docs/benchmarks stay in project repos.\n\n---\n\n### homebrew-tap (PUBLIC)\n**Purpose**: Homebrew tap for sreniatnoc tools.\n**Repo**: https://github.com/sreniatnoc/homebrew-tap\n\n**Usage**:\n```bash\nbrew tap sreniatnoc/tap\nbrew install k8sify\n```\n"
    },
    {
      "org": "sreniatnoc",
      "repo": "rusd",
      "tier": 3,
      "path": ".skills/kind-validation.md",
      "name": "kind-validation.md",
      "content": "# Kind Cluster Validation for rusd\n\n**Last Updated**: 2026-02-10\n**K8s Version**: v1.35.0 (kind v0.31.0)\n**Status**: WORKING - Full K8s CRUD operations validated\n\n---\n\n## Kind Configuration\n\nFile: `/tmp/kind-rusd.yaml`\n\n```yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnetworking:\n  apiServerPort: 6443\nnodes:\n  - role: control-plane\n    kubeadmConfigPatches:\n      - |\n        kind: ClusterConfiguration\n        etcd:\n          external:\n            endpoints:\n              - http://host.docker.internal:2479\n```\n\nThis config tells Kind to use an external etcd at `http://host.docker.internal:2479` instead of spinning up its own etcd pod. The `host.docker.internal` DNS name resolves to the host machine from inside Docker containers.\n\n---\n\n## Launch Commands\n\n### 1. Start rusd on the host\n\n```bash\ncd /Users/shaileshpant/src/gh-orgs/sreniatnoc/rusd\ncargo run --release -- --listen-client-urls http://0.0.0.0:2479 --advertise-client-urls http://0.0.0.0:2479\n```\n\nOr use the pre-built binary:\n\n```bash\n./rusd --listen-client-urls http://0.0.0.0:2479 --advertise-client-urls http://0.0.0.0:2479\n```\n\n### 2. Create the Kind cluster\n\n```bash\nkind create cluster --name rusd-test --config /tmp/kind-rusd.yaml\n```\n\n### 3. Verify the cluster\n\n```bash\nkubectl cluster-info --context kind-rusd-test\nkubectl get nodes\nkubectl get pods -A\n```\n\n### 4. Teardown\n\n```bash\nkind delete cluster --name rusd-test\n```\n\n---\n\n## etcdctl Compatibility Matrix\n\nAll commands tested with:\n```bash\nexport ETCDCTL_API=3\nexport ETCDCTL_ENDPOINTS=http://localhost:2479\n```\n\n### KV Operations - ALL WORK\n\n| Command | Status | Notes |\n|---------|--------|-------|\n| `etcdctl put foo bar` | OK | Returns \"OK\" |\n| `etcdctl get foo` | OK | Returns key + value |\n| `etcdctl get --prefix foo` | OK | Returns all keys with prefix |\n| `etcdctl del foo` | OK | Returns delete count |\n\n### Watch Operations - ALL WORK\n\n| Command | Status | Notes |\n|---------|--------|-------|\n| `etcdctl watch foo` | OK | Receives PUT events |\n| `etcdctl watch --prefix /` | OK | Receives all events |\n| PUT events | OK | Delivered with key, value, mod_revision |\n| DELETE events | OK | Delivered with key, mod_revision |\n| prev_kv in events | OK | Previous key-value included in watch events |\n\n### Lease Operations - ALL WORK\n\n| Command | Status | Notes |\n|---------|--------|-------|\n| `etcdctl lease grant 300` | OK | Returns lease ID and TTL |\n| `etcdctl lease list` | OK | Lists active lease IDs |\n| `etcdctl lease timetolive <id>` | OK | Returns remaining TTL |\n| `etcdctl lease revoke <id>` | OK | Revokes the lease |\n\n### Cluster Operations\n\n| Command | Status | Notes |\n|---------|--------|-------|\n| `etcdctl member list` | OK | Returns single-node member |\n| `etcdctl endpoint health` | OK | Reports healthy |\n| `etcdctl endpoint status` | FAIL | Panics etcdctl (divide by zero) |\n\n### Auth Operations\n\n| Command | Status | Notes |\n|---------|--------|-------|\n| `etcdctl user add` | OK | Creates user |\n| `etcdctl role add` | OK | Creates role |\n| `etcdctl user list` | EMPTY | Returns empty (known gap) |\n| `etcdctl role list` | EMPTY | Returns empty (known gap) |\n\n### Txn Operations\n\n| Command | Status | Notes |\n|---------|--------|-------|\n| CAS (Compare-and-Swap) | OK | Compare operations work correctly |\n\n---\n\n## Known Limitations\n\n### \"Too large resource version\" errors (NON-FATAL)\n- K8s occasionally logs: `\"Too large resource version\"`\n- These are non-fatal; Kubernetes retries automatically and operations succeed\n- Root cause: revision numbering diverges from what K8s informers expect in some edge cases\n\n### Revision-based range reads (APPROXIMATE)\n- MVCC only stores the latest version of each key (not full history)\n- Range reads with a specific revision return current data, not historical snapshots\n- This is sufficient for K8s operation but not fully etcd-compatible\n\n### Integration tests broken (12/12 FAIL)\n- Tests use HTTP/JSON endpoints (`/v3/kv/put`, `/health`)\n- rusd is a pure gRPC server with no HTTP gateway\n- Tests need rewrite to use tonic gRPC client\n- Port conflict: all tests hardcode port 12379\n\n---\n\n## K8s Operations Validated\n\nAll of the following operations were tested and confirmed working on the Kind cluster with rusd as the backing store:\n\n| Operation | Command | Status |\n|-----------|---------|--------|\n| Create namespace | `kubectl create namespace test-rusd` | OK |\n| Create configmap | `kubectl create configmap test-cm --from-literal=key=value -n test-rusd` | OK |\n| Create secret | `kubectl create secret generic test-secret --from-literal=password=secret -n test-rusd` | OK |\n| Create serviceaccount | `kubectl create serviceaccount test-sa -n test-rusd` | OK |\n| Create role | `kubectl create role test-role --verb=get --resource=pods -n test-rusd` | OK |\n| Create rolebinding | `kubectl create rolebinding test-rb --role=test-role --serviceaccount=test-rusd:test-sa -n test-rusd` | OK |\n| Create deployment | `kubectl create deployment nginx --image=nginx:alpine -n test-rusd` | OK |\n| Scale deployment | `kubectl scale deployment nginx --replicas=3 -n test-rusd` | OK |\n| Rolling update | `kubectl set image deployment/nginx nginx=nginx:latest -n test-rusd` | OK |\n| Create service | `kubectl expose deployment nginx --port=80 -n test-rusd` | OK |\n| Pod exec | `kubectl exec -it <pod> -n test-rusd -- /bin/sh` | OK |\n| Delete namespace | `kubectl delete namespace test-rusd` | OK |\n\nAll K8s CRUD operations work end-to-end with rusd as the etcd backend.\n"
    }
  ],
  "memories": [
    {
      "org": "engram-hq",
      "repo": ".memory",
      "path": "sessions/2026-02-11-platform-scaffold.md",
      "name": "2026-02-11-platform-scaffold.md",
      "content": "---\ndate: \"2026-02-11\"\norg: engram-hq\nrepo: engram-web\ngoal: Scaffold the entire Engram platform from zero to 6 repos with CI\ntype: session\nmodel: claude-opus-4-6\ncost_note: \"shared session with multi-node-raft; see that memory for cost data\"\n---\n\n# Session: Engram Platform Scaffold\n\n**Date**: 2026-02-11\n**Org**: engram-hq\n**Repo**: engram-web, engram-sdk, engram-ios, releases, .skills, roadmap\n**Goal**: Build the Engram visual skill/memory browser from scratch\n\n## Summary\n\nCreated the engram-hq GitHub organization with 6 repositories. Built a full-stack platform: Next.js 15 web app with 15 API endpoints and 9 dashboard pages, TypeScript SDK for agent metrics, SwiftUI iOS app, and a GitHub Pages landing site. All CI pipelines green.\n\n## Phase 1: Web App Foundation\n\n- Initialized Next.js 16 project with Auth.js v5, Drizzle ORM, Turso (SQLite)\n- Designed 10-table schema: users, skills, memories, organizations, repositories, agent_sessions, agent_cost_daily, model_pricing, api_keys, sync_events\n- Built 15 REST API endpoints under /api/v1/\n- ReactMarkdown v10 breaking change: dropped className prop, wrapped in div\n- Edge middleware can't import Node crypto module, used simple NextResponse middleware\n\n## Phase 2: Dashboard UI\n\n- 9 pages: dashboard, skills (tree+list), skill detail, memories timeline, memory detail, organizations, analytics, search, settings\n- All pages wired to real Drizzle queries, not mock data\n- Recharts for analytics visualization (cost trends, model breakdown)\n- shadcn/ui component library with dark theme\n\n## Phase 3: GitHub Sync Engine\n\n- Scans user's GitHub orgs for .skills/ and .memory/ repos\n- Recursive file traversal via GitHub Content API\n- Frontmatter parsing for skill metadata\n- Content hash diffing for incremental sync\n- Tracks sync events with API call counts and duration\n\n## Phase 4: SDK and iOS\n\n- TypeScript SDK (@engram-hq/sdk) with batching, retry, cost tracking\n- SwiftUI iOS app with OAuth, Keychain, Charts, 5-tab navigation\n- Both built from scratch, no templates\n\n## Phase 5: CI and Testing\n\n- engram-web: 4 CI jobs (lint, typecheck, test, build)\n- engram-sdk: 3 CI jobs\n- engram-ios: 2 CI jobs (build+test, lint)\n- Total: 229 tests across all repos\n\n## Key Decisions\n\n- **Turso over Supabase**: SQLite semantics, edge-native, simpler schema\n- **Auth.js v5 over Clerk**: Self-hosted, GitHub-first auth flow\n- **Drizzle over Prisma**: Better SQLite support, type-safe queries, smaller bundle\n- **xcodegen over manual .xcodeproj**: Reproducible project generation, no merge conflicts\n\n## What Failed\n\n- Turso Cloud DB not provisioned (needs browser)\n- GitHub OAuth App not registered (needs browser)\n- iOS simulator runtime not installed locally (8.4GB download)\n"
    },
    {
      "org": "engram-hq",
      "repo": ".memory",
      "path": "sessions/2026-02-12-live-demo-skills.md",
      "name": "2026-02-12-live-demo-skills.md",
      "content": "---\ndate: \"2026-02-12\"\norg: engram-hq\nrepo: releases\ngoal: Build live demo on landing page with real GitHub data\ntype: session\nmodel: claude-opus-4-6\ninput_tokens: 48704\noutput_tokens: 6327\ncache_read_tokens: 23628203\ncache_creation_tokens: 1663789\ncost_usd: 28.85\napi_calls: 254\ncost_note: \"equivalent API cost (Max plan)\"\n---\n\n# Session: Live Demo with Real Data\n\n**Date**: 2026-02-12\n**Org**: engram-hq\n**Repo**: releases\n**Goal**: Add a live demo section to the landing page that fetches real skills from public GitHub repos\n\n## Summary\n\nBuilt a fully functional live demo on the Engram landing page that fetches real data from public GitHub repos using the unauthenticated API. Configurable via URL params, client-side markdown rendering, session storage caching.\n\n## The Challenge\n\nAll .skills repos were private. Unauthenticated GitHub API has 60 req/hr rate limit. Needed to show real data without mocking or hardcoding.\n\n## Solution\n\n1. Made engram-hq/.skills repo public (has org-knowledge/SKILL.md)\n2. sreniatnoc/rusd already has a public .skills/ directory\n3. Client-side JavaScript with sessionStorage caching (15min TTL)\n4. URL override via ?orgs=org1,org2 parameter for swappable demo orgs\n\n## Architecture\n\n- DEMO_CONFIG with configurable orgs (default: engram-hq, sreniatnoc)\n- ghFetch() wraps GitHub REST API with caching\n- ghRawFetch() fetches raw file content from raw.githubusercontent.com\n- scanOrgs() discovers .skills repos, .memory repos, and repo-level .skills/ dirs\n- collectMdFiles() does recursive directory traversal\n- renderTree() builds interactive sidebar grouped by org\n- renderMarkdown() client-side markdown to HTML (no deps): frontmatter, code blocks, headers, tables, lists\n- loadFile() fetches and renders a selected skill with metadata badges\n- Auto-selects first skill on page load\n\n## What Worked\n\n- GitHub Content API returns directory listings as JSON arrays\n- raw.githubusercontent.com serves file content without API rate limits\n- sessionStorage prevents redundant API calls within a browsing session\n- Pure JavaScript markdown renderer handles 95% of cases without a library\n\n## What Didn't Work Initially\n\n- GitHub API returns 404 for private repos (expected) - had to make repos public\n- Initial approach tried GitHub Trees API but it requires auth for private repos\n"
    },
    {
      "org": "engram-hq",
      "repo": ".memory",
      "path": "sessions/2026-02-12-production-readiness.md",
      "name": "2026-02-12-production-readiness.md",
      "content": "---\ndate: \"2026-02-12\"\norg: engram-hq\nrepo: engram-web, engram-ios\ngoal: Make both web and iOS apps deployment-ready for real users\ntype: session\nmodel: claude-opus-4-6\ninput_tokens: 5444\noutput_tokens: 54407\ncache_read_tokens: 43430430\ncache_creation_tokens: 2447556\ncost_usd: 47.58\napi_calls: 457\ncost_note: \"equivalent API cost (Max plan)\"\n---\n\n# Session: Production Readiness\n\n**Date**: 2026-02-12\n**Org**: engram-hq\n**Repo**: engram-web, engram-ios\n**Goal**: Make both apps fully qualified for local deployment and App Store\n\n## Summary\n\nAdded local SQLite dev mode so the web app works without Turso Cloud. Created auto-migration that sets up all 10 tables on first access. Added Xcode project infrastructure for the iOS app: project.yml, Info.plist, entitlements, privacy manifest, app icon. Both apps now pass CI with full test coverage.\n\n## Phase 1: Web Local Dev Mode\n\n### Problem\nWeb app required Turso Cloud account and GitHub OAuth app just to start locally. No setup docs, no .env.example. Another developer couldn't clone and run.\n\n### Solution\n- Modified lib/db/client.ts to detect file: URLs for local SQLite\n- drizzle.config.ts now auto-switches between sqlite and turso dialects\n- Created setup script (pnpm setup) that creates tables + seeds model pricing\n- Added auto-migration in dashboard layout (ensureMigrated())\n- Created .env.example with documented config\n- Created SETUP.md with 5-minute quickstart guide\n\n### Key Insight\n@libsql/client already supports file: protocol natively. The fix was just conditional config, not a new dependency.\n\n## Phase 2: iOS Xcode Project\n\n### Problem\nApp only had Package.swift (SPM library). No .xcodeproj means no device install, no App Store submission. Missing: app icons, Info.plist, privacy manifest, entitlements.\n\n### Solution\n- Created project.yml for xcodegen (reproducible .xcodeproj generation)\n- Info.plist: Bundle ID com.engram-hq.engram, URL scheme engram://, launch screen\n- Engram.entitlements: Keychain access + App Group\n- PrivacyInfo.xcprivacy: declares UserDefaults, no tracking\n- AppIcon.png: 1024x1024 programmatically generated (purple E on dark background)\n- Updated CI: xcodegen install + generate + xcodebuild build + test on simulator\n\n### What Failed\n- iOS 26.2 simulator runtime not installed locally (8.4GB). Agent tried downloading it, had to abort.\n- Workaround: CI has simulators, verified build+test there. Local testing via Xcode will prompt download.\n\n## Phase 3: Live Demo Enhancement\n\n- Added webhook integration tests (9 tests, PR #5)\n- Added RecCall Tier 4 sync endpoint (PR #7)\n- Added Drizzle migration files (PR #6)\n- Live demo on landing page fetches real skills from public GitHub repos\n\n## Test Coverage\n\n| Repo | Tests | CI Status |\n|------|-------|-----------|\n| engram-web | 149 | Green (4 jobs) |\n| engram-ios | 59 | Green (SPM + Xcode + simulator) |\n| engram-sdk | 21 | Green (3 jobs) |\n| **Total** | **229** | **All green** |\n\n## Lessons Learned\n\n1. tsx (esbuild) doesn't support top-level await in CJS mode - wrap in async main()\n2. xcodegen is the right tool for reproducible iOS projects - keeps .xcodeproj out of git\n3. Free Apple Developer signing expires after 7 days - need paid program for permanent install\n4. Auto-migration at app startup is better UX than requiring a separate setup step\n"
    },
    {
      "org": "sreniatnoc",
      "repo": ".memory",
      "path": "sessions/2026-02-09-rusd-kind-validation.md",
      "name": "2026-02-09-rusd-kind-validation.md",
      "content": "---\ndate: \"2026-02-09\"\norg: sreniatnoc\nrepo: rusd\ngoal: Validate rusd as etcd replacement in Kind K8s cluster\ntype: session\nmodel: claude-opus-4-6\ninput_tokens: 2750\noutput_tokens: 98414\ncache_read_tokens: 147402727\ncache_creation_tokens: 5627095\ncost_usd: 132.45\napi_calls: 1513\ncost_note: \"equivalent API cost (Max plan); session spanned Feb 9-10\"\n---\n\n# Session: rusd Kind Cluster Validation\n\n**Date**: 2026-02-09 to 2026-02-10\n**Org**: sreniatnoc\n**Repo**: rusd\n**Goal**: Implement Watch event delivery, fix txn CAS, validate rusd as etcd replacement in Kind K8s cluster\n\n## Summary\n\nImplemented Watch event delivery, txn CAS operations, prev_kv in Watch events, graceful shutdown with serve_with_shutdown(), and HTTP/2 keepalive. Successfully validated rusd as an external etcd backend for a Kind cluster running Kubernetes v1.35. All K8s CRUD operations work including deployments, scaling, rolling updates, pod exec, and namespace lifecycle.\n\n## Phase 1: Initial Validation Attempt\n\nAttempted full validation of rusd for Kubernetes compatibility. Native build and unit tests pass. etcdctl compatibility partial. Kind cluster creation failed due to unimplemented Watch event delivery.\n\n### What Worked\n- cargo build --release succeeds (44 warnings, 0 errors)\n- Docker build succeeds after Dockerfile fixes (167MB image)\n- 40/40 unit tests PASS\n- etcdctl KV (put/get/del), Lease (grant/list/timetolive/revoke), Endpoint health\n\n### What Failed\n- Watch API: acknowledged but never delivered events\n- Kind cluster: kube-apiserver 403 Forbidden (RBAC can't bootstrap without Watch)\n\n## Phase 2: Bugs Found and Fixed\n\n1. **next_revision() returning old value** - returning pre-increment instead of post-increment\n2. **Proto field numbers wrong** - events field was 7 but etcd expects 11, prev_kv missing\n3. **Initial revision 0** - etcd starts at 1, K8s expects >= 1\n4. **Transport error on shutdown** - switched to serve_with_shutdown() for graceful draining\n5. **prev_kv missing in Watch events** - K8s informers need prev_kv for change detection\n6. **Txn compares always succeeding** - implemented actual comparison logic for CAS\n\n## Final State\n\nFull K8s CRUD validated: namespace, configmap, secret, serviceaccount, role, rolebinding, deployment create/scale/rolling-update, service, pod exec. Kind cluster with K8s v1.35 bootstraps and runs all control plane components with rusd as external etcd.\n"
    },
    {
      "org": "sreniatnoc",
      "repo": ".memory",
      "path": "sessions/2026-02-10-production-hardening.md",
      "name": "2026-02-10-production-hardening.md",
      "content": "---\ndate: \"2026-02-10\"\norg: sreniatnoc\nrepo: rusd\ngoal: Add TLS/mTLS, CI pipeline, and API compatibility layer\ntype: session\nmodel: claude-opus-4-6\ninput_tokens: 4861\noutput_tokens: 7804\ncache_read_tokens: 8846660\ncache_creation_tokens: 299245\ncost_usd: 7.64\napi_calls: 130\ncost_note: \"equivalent API cost (Max plan); follow-up session to main Feb 10 work\"\n---\n\n# Session: Production Hardening\n\n**Date**: 2026-02-10\n**Org**: sreniatnoc\n**Repo**: rusd\n**Goal**: Make rusd production-grade with TLS, CI, benchmarks, and API compatibility\n\n## Summary\n\nAdded TLS/mTLS support, built a comprehensive CI pipeline with 8 jobs, rewrote integration tests from HTTP to gRPC, added Criterion benchmarks, and achieved 10x faster Kubernetes deploy+scale versus etcd v3.6.7. Merged as PR #1 feat/production-ready.\n\n## Phase 1: TLS/mTLS\n\n- Implemented native TLS using rustls (no OpenSSL dependency)\n- Server-side TLS with PEM cert/key\n- Mutual TLS (mTLS) with client certificate verification\n- Auto-generated test certificates via scripts/gen-certs.sh\n- 8 dedicated TLS tests covering connect, reject, mTLS scenarios\n\n## Phase 2: CI Pipeline\n\nBuilt GitHub Actions CI with 8 parallel jobs:\n- cargo build + clippy lint\n- 48 unit tests\n- 12 integration tests (rewritten from HTTP to gRPC)\n- 8 TLS/mTLS tests\n- 32 Criterion benchmarks\n- Docker build verification\n- K8s validation via Kind cluster (34 test points)\n\nAll 8 jobs green, no continue-on-error.\n\n## Phase 3: Benchmarks\n\nCreated Criterion benchmarks measuring:\n- KV put/get/delete throughput\n- Watch event delivery latency\n- Txn CAS operations per second\n- Prefix scan performance\n\nResults vs etcd v3.6.7:\n- **10x faster** deploy + scale operations\n- **6x faster** rolling updates\n- **2x less memory** at idle\n\n## Lessons Learned\n\n- rustls is simpler than OpenSSL for Rust projects - no system dependency, pure Rust\n- Criterion benchmarks need --bench flag in CI, not cargo test\n- Kind cluster tests need wait_for_leader (election takes ~3s)\n"
    },
    {
      "org": "sreniatnoc",
      "repo": ".memory",
      "path": "sessions/2026-02-11-k8s-test-suite.md",
      "name": "2026-02-11-k8s-test-suite.md",
      "content": "---\ndate: \"2026-02-11\"\norg: sreniatnoc\nrepo: rusd\ngoal: Build comprehensive K8s validation test suite\ntype: session\nmodel: claude-opus-4-6\ncost_note: \"shared session with multi-node-raft; see that memory for cost data\"\n---\n\n# Session: K8s Test Suite\n\n**Date**: 2026-02-11\n**Org**: sreniatnoc\n**Repo**: rusd\n**Goal**: Automated K8s validation with 34 test points in CI\n\n## Summary\n\nBuilt a comprehensive Kubernetes validation script that runs rusd as an external etcd backend for a Kind cluster. The script tests 34 operations covering namespace lifecycle, RBAC, deployments, scaling, rolling updates, services, and pod exec. Runs in CI on every push.\n\n## Test Coverage\n\n34 test points organized into categories:\n- **Namespace**: create, verify, delete (3 tests)\n- **RBAC**: role, rolebinding, serviceaccount CRUD (6 tests)\n- **ConfigMap/Secret**: create, read, update, delete (8 tests)\n- **Deployment**: create, verify pods, scale up/down (6 tests)\n- **Rolling Update**: image update, rollout status, verify (4 tests)\n- **Service**: expose, verify endpoints (3 tests)\n- **Pod Operations**: exec, logs, port-forward (4 tests)\n\n## Key Gotchas\n\n- Kind host.docker.internal works from Docker containers on macOS Docker Desktop\n- etcdctl --count-only is broken in simple/JSON mode, use --keys-only with grep -c\n- CI multi-node tests need wait_for_leader, not just endpoint health\n- grep -c pattern || echo \"0\" causes double output, use || true instead\n"
    },
    {
      "org": "sreniatnoc",
      "repo": ".memory",
      "path": "sessions/2026-02-11-multi-node-raft.md",
      "name": "2026-02-11-multi-node-raft.md",
      "content": "---\ndate: \"2026-02-11\"\norg: sreniatnoc\nrepo: rusd\ngoal: Implement multi-node Raft consensus with real replication\ntype: session\nmodel: claude-opus-4-6\ninput_tokens: 28482\noutput_tokens: 19043\ncache_read_tokens: 36971685\ncache_creation_tokens: 1639237\ncost_usd: 35.50\napi_calls: 398\ncost_note: \"equivalent API cost (Max plan); session shared with k8s-test-suite and platform-scaffold\"\n---\n\n# Session: Multi-Node Raft Consensus\n\n**Date**: 2026-02-11\n**Org**: sreniatnoc\n**Repo**: rusd\n**Goal**: Enable multi-node cluster with Raft leader election, log replication, and failover\n\n## Summary\n\nImplemented end-to-end Raft consensus turning rusd from a single-node database into a distributed cluster. Leader election, log replication, heartbeat protocol, and follower forwarding all work. 7 multi-node integration tests pass including leader failover scenarios. Merged as PR #3 feat/e2e-raft-replication.\n\n## Phase 1: Raft Core\n\n- Fixed Send trait issue with parking_lot::Mutex by switching to tokio::sync::Mutex\n- Implemented leader election with randomized timeouts (150-300ms)\n- AppendEntries RPC for log replication with consistency checks\n- RequestVote RPC with term comparison and log freshness checks\n- Heartbeat protocol to maintain leadership\n\n## Phase 2: State Machine Integration\n\n- Raft log entries applied to MVCC storage engine\n- Write operations forwarded from followers to leader via gRPC\n- Leader replicates committed entries to all followers\n- Followers apply entries in order after commit index advances\n\n## Phase 3: Multi-Node Tests\n\n7 integration tests covering:\n1. Three-node cluster formation\n2. Leader election within 5 seconds\n3. Write replication to all nodes\n4. Read consistency across followers\n5. Leader step-down and re-election\n6. Network partition recovery\n7. Stress test with concurrent writes\n\n## Key Decisions\n\n- Used gRPC for inter-node transport (reuses existing tonic infrastructure)\n- Randomized election timeouts prevent split-brain scenarios\n- Follower forwarding is transparent to clients - any node accepts writes\n- CI runs multi-node tests with reduced parallelism (5 streams) for stability\n\n## What's Left\n\n- Snapshot transfer for new node catch-up\n- Dynamic membership changes (AddNode/RemoveNode)\n- Chaos testing with random network partitions\n"
    }
  ],
  "generated_at": "2026-02-13T06:37:27Z"
}